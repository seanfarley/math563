#+title: Homework 3
#+date: Tuesday, February 24, 2022
#+options: toc:nil
#+latex_header: \usepackage{enumitem}
#+latex_header: \setlist[enumerate,1]{label=$\alph*)$}
#+latex_header: \usepackage{amsthm}
#+latex_header: \usepackage{tikz}
#+latex_header: \usetikzlibrary{arrows,intersections}
#+latex_header: \allowdisplaybreaks
#+latex_header: \everymath{\displaystyle}

#+begin_src latex-macros
\newenvironment{problem}{\begin{itshape}}{\end{itshape}}
\newenvironment{solution}{\begin{proof}[Solution]}{\end{proof}}
\newcommand{\Xbar}{\overline{X}}
\newcommand{\randsamp}{X_1, \ldots, X_n}
\newcommand{\iid}{\randsamp \sim\text{iid}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\var}{\text{Var}}
#+end_src

* Exercise 1

#+begin_problem
Let $X_1, X_2, \ldots, X_n$ be a random sample from a Gaussian distribution with mean
$\mu$ and variance $\sigma^2 < \infty$. Show that  $\sum_{i=1}^{n} X_i^2$ is a sufficient statistic for $\mu$.
#+end_problem

* Exercise 6.5.7

#+begin_problem
Let $f(x, y | \theta_1, \theta_2, \theta_3, \theta_4)$ be the bivariate pdf for the uniform
distribution on the rectangle with lower left corner $(\theta_1, \theta_2)$ and the upper
right corner $(\theta_3, \theta_4)$ in $\mathbb{R}^2$. The parameters satisfy $\theta_1 < \theta_3$ and $\theta_2
< \theta_4$. Let $(X_1, Y_1), \ldots, (X_n, Y_n)$ be a random sample from this pdf. Find a
four-dimensional sufficient statistic for $(\theta_1, \theta_2, \theta_3, \theta_4)$.
#+end_problem

#+begin_solution
Let's take a look at,

\begin{tikzpicture}
  \coordinate (O) at (0,0);

  \draw[->] (-0.3,0) -- (8,0) coordinate (xmax);
  \draw[->] (0,-0.3) -- (0,5) coordinate[label = {right:$\mathbb{R}^2$}] (ymax);
  \path[name path=x] (0.3,0.5) -- (6.7,4.7);
  \path[name path=y] plot[smooth] coordinates {(-0.3,2) (2,1.5) (4,2.8) (6,5)};

  \scope[name intersections = {of = x and y, name = i}]
    \fill[gray!20] (i-1) -- (i-2 |- i-1) -- (i-2) -- (i-1 |- i-2);
    \draw (i-1) node[dot, label = {south west:$(\theta_1, \theta_2)$}] (i-1) {};
    \path (i-2) node[dot, label = {north east:$(\theta_3, \theta_4)$}] (i-2) {} -- (i-2 |- i-1)
      node[dot] (i-12) {};
    \draw[blue, <->] (i-2) -- node[right] {$|\theta_4 - \theta_2|$} (i-12);
    \draw[blue, <->] (i-1) -- node[below] {$|\theta_3 - \theta_1|$} (i-12);

    \node (area) at (8,4.4) {$A=(\theta_3 - \theta_1)(\theta_4 - \theta_2)$};
    \draw[->] (area.west) to[bend right] (3,2.5);
  \endscope
\end{tikzpicture}

#+end_solution

* Exercise 6.5.12

#+begin_problem
A natural ancillary statistic in most problems is the /sample size/. For
example, let $N$ be a random variable taking values $1, 2, \ldots$ with known
probabilities $p_1, p_2, \ldots$, where $\sum p_i = 1$. Having observed $N = n$, perform
$n$ Bernoulli trials with success probability $\theta$, getting $X$ successes.

1) Prove that the pair $(X, N)$ is minimal sufficient and $N$ is ancillary for
   $\theta$. (Note the similarity to some of the hierarchical models discussed in
   Section 4.4).
1) Prove that the estimator $X/N$ is unbiased for $\theta$ and has variance $\theta(1-\theta)\E(1/N)$.
#+end_problem

* Exercise 6.5.15

#+begin_problem
Let $\iid \, n(\theta, a\theta^2)$, where $a$ is a known constant and $\theta > 0$.

1) Show the parameter space does not contain a two-dimensional open set.
1) Show that the statistic $T = (\Xbar, S^2)$ is a sufficient statistic for $\theta$,
   but the family of distributions is not complete.
#+end_problem

* Exercise 6.5.19

#+begin_problem
The random variable $X$ takes the values $0, 1, 2$ according to one of the
following distributions:

#+caption: Distributions
#+name: tab:dists
|                | $P(X = 0)$ | $P(X = 1)$ | $P(X = 2)$    |                       |
|----------------+------------+------------+---------------+-----------------------|
| Distribution 1 | $p$        | $3p$       | $1 - 4p$      | $0 < p < \frac{1}{4}$ |
| Distribution 2 | $p$        | $p^2$      | $1 - p - p^2$ | $0 < p < \frac{1}{2}$ |

In each case determine whether the family of distributions of $X$ is complete.
#+end_problem

* Exercise 6.5.21

#+begin_problem
Let $X$ be one observation from the pdf

\begin{equation}
\label{eq:foo}
f(X|\theta) = \left( \frac{\theta}{2} \right)^{|x|} (1 - \theta)^{1 - |x|}, \quad x=-1, 0, 1, \quad 0 \le \theta \le 1.
\end{equation}

1) Is $X$ a complete sufficient statistic?
1) Is $\left| X \right|$ a complete sufficient statistic?
1) Does $f(x | \theta)$ belong to the exponential class?
#+end_problem

* Exercise 6.5.30

#+begin_problem
Let $\randsamp$ be a random sample from the pdf $f(x|\mu) = e^{-(x-\mu)}$, where $-\infty
< \mu < x < \infty$.

1) Show that $X_{(1)} = \min_i X_i$ is a complete sufficient statistic.
1) Use Basu's Theorem to show that $X_{(1)}$ and $S^2$ are independent.
#+end_problem

* Exercise 6.5.36

#+begin_problem
One advantage of using a minimal sufficient statistic is that unbiased
estimators will have smaller variance, as the following exercise will show.
Suppose that $T_1$ is sufficient and $T_2$ is minimal sufficient, $U$ is an
unbiased estimator of $\theta$, and define $U_1 = \E(U | T_1)$ and $U_2 = \E(U | T_2)$.

1) Show that $U_2 = \E(U_1  | T_2)$.
1) Now use the conditional variance formula (Theorem 4.4.7) to show that
   $\var \, U_2 \le \var \, U_1$.
#+end_problem
